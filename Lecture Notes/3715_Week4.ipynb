{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**\n",
        "\n",
        "\n",
        "*   Supervised learning\n",
        "  * Given: feature and ground truth value of the sample (training set)\n",
        "  * Goal: predict labels (classification)\n",
        "*   Unsupervised learning\n",
        "  * Given: features only, no labels\n",
        "  * Goal: find meaningful groups (clustering)"
      ],
      "metadata": {
        "id": "4mQpIihL312I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supervised Learning**\n",
        "* given n samples {(x1,y1),...,(xn,yn)}\n",
        "* learn a mapping function f(x) -> y\n",
        "  * y is continuous: regression;\n",
        "  * y is discrete: classification"
      ],
      "metadata": {
        "id": "aEQHY6G_5wvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regression Applications**\n",
        "* Stock predictions\n",
        "* Weather prediction"
      ],
      "metadata": {
        "id": "DiJBQ17l70i5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build linear regression model**\n",
        "* learn a mapping function f(x) -> y\n",
        "* f(x) is a linear combination of input features\n",
        "```\n",
        "  f(x_i) = w0 + w1(x_i,1) + w2(x_i,2) + ... + wd(x_i,d)\n",
        "  x_i = (x_i,1, x_i,2, ... , x_i,d) is the feature of the i-th sample\n",
        "  w = (w0, w1, w2, ..., wd) is the model weight\n",
        "  w0 is the *bias*\n",
        "```\n",
        "* f(x_i) = w^T(x_i)"
      ],
      "metadata": {
        "id": "3gnYPQVe8Quq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model optimization**\n",
        "* minimize prediction error\n",
        "* Loss function = min_w (1/n)sum(y - f(x))^2 = min 1/n||y-Xw||^2\n",
        "\n",
        "\n",
        "```\n",
        "[1, x1, x2, ..., xd][w0]\n",
        "[1, ..., ..., ... ] [...]\n",
        "[1, ..., ..., ... ] [wd]\n",
        "```\n",
        "* column of 1's lets w0 be included\n",
        "* find weight where derivative of loss function is 0\n",
        "* w = (X^T*X)^-1 *X^Ty"
      ],
      "metadata": {
        "id": "XwDKUeqs_H0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss functions**\n",
        " * Mean absolute error (MAE)\n",
        " * Mean squared error (MSE)\n",
        " * Root mean squared error (RMSE)"
      ],
      "metadata": {
        "id": "bSl6lzQyLiNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient descent**\n",
        "\n",
        "machine learning is an optimization problem\n",
        "\n",
        "find a model parameter to minimize the loss function\n",
        "\n",
        "iterative process"
      ],
      "metadata": {
        "id": "RPzrE7SFNH-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and Testing data**"
      ],
      "metadata": {
        "id": "twetpnQbQcaz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSsWsLx43yHN"
      },
      "outputs": [],
      "source": [
        "# split samples\n",
        "\n",
        "house_fea = df.drop('median_house_value', axis=1).values\n",
        "house_price = df['median_house_value'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(house_fea, house_price, test_size = 0.2, random_state = 42)\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train = normalizer.fit_transform(X_train)\n",
        "X_test = normalizer.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "RSFNIqFORCtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"bias: \" + str(lr.intercept_))\n",
        "print(\"coeffs: \"+ str(lr.coef_)) #gives weight for each feature"
      ],
      "metadata": {
        "id": "_ZdxZM2xREf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model\n",
        "y_train_pred = lr.predict(X_train)\n",
        "\n",
        "mae = mean_absolute_error(y_train_pred, y_train)\n",
        "mse = mean_squared_error(y_train_pred, y_train)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Prediction for training set: \")\n",
        "print(\"MAE: {}\".format(mae))\n",
        "print(\"MSE: {}\".format(mse))\n",
        "print(\"RMSE: {}\".format(rmse))"
      ],
      "metadata": {
        "id": "AeHyJ9uWRi0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['House1', 'House2', 'House3', 'House4', 'House5']\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, y_test[0:5], width, label= \"ground truth\")\n",
        "rects2 = ax.bar(x + width/2, y_test_pred[0:5], width, label= \"predicted\")\n",
        "\n",
        "ax.set_ylabel(\"Price\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "kYwoOmGTSLpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to fit nonlinear data?**\n",
        "\n",
        "-- apply a nonlinear transformation to features\n",
        "\n",
        "-- can increase the order of the model\n",
        "\n",
        "**Overfittng**: errors on training data are very small, but errors on new points are likely to be large"
      ],
      "metadata": {
        "id": "Y-ZXSucCSK20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to avoid overfitting**\n",
        "* add a regularization term\n",
        "* make some w_i very small or approach to zero"
      ],
      "metadata": {
        "id": "jlUVkrxnZG1u"
      }
    }
  ]
}