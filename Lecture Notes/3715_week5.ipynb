{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Classification**\n",
        "\n",
        "Optimize the likelihood function // minimize the negative log-likelihood function"
      ],
      "metadata": {
        "id": "gDBQtuEVW5ry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross-entropy loss function\n",
        "\n",
        "min of $- sum(y_ilog(p_i) + (1-y_i)log(1-p_i))$"
      ],
      "metadata": {
        "id": "cVsYpY0EYfJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation for Binary Classification\n",
        "\n",
        "**Balanced data**\n",
        "\n",
        "When data is balanced (equally positive and negative), use the classification accuracy\n",
        "\n",
        "$accuracy = number of correct predictions / number of total predictions$"
      ],
      "metadata": {
        "id": "LmFjoBxd83tH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ```True positive: ``` prediction is positive, ground truth is positive\n",
        "* ```False positive```: prediction is positive, ground truth is negative\n",
        "* ```False negative```: prediction is negative, ground truth is positive\n",
        "* ```True negative```: prediction is negative, ground truth is negative\n",
        "\n",
        "$ accuracy = (TP + TN) / (TP + FP + TN + GN) $"
      ],
      "metadata": {
        "id": "E49CR0za9u6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imbalanced data**\n",
        "When data is imbalanced, use the recall or precision\n",
        "\n",
        "$recall = TP / (TP + FN)$\n",
        "\n",
        "$precision = TP/ (TP + FP)$"
      ],
      "metadata": {
        "id": "2MQhsYEL-z3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to care about recall?\n",
        "* ex. Covid-19 diagnosis\n",
        "* important to find all positive samples\n",
        "\n",
        "When to care about precision?\n",
        "* ex. Google search\n",
        "* users are sensitive to prediction error"
      ],
      "metadata": {
        "id": "yHXpeuDBBRrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relationship between recall & precision\n",
        "\n",
        "``` F1 score: ``` harmonic mean of recall and precision, conveys balance of recall & precision\n",
        "\n",
        "$F1 score = (2 * recall * precision ) / ( recall + precision )$"
      ],
      "metadata": {
        "id": "Kd3ASWOVBmY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess\n",
        "X, y = datasets.load_iris(return_X_y = True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.1,\n",
        "                                                    random_state = 0)\n",
        "\n",
        "#normalize\n",
        "normalizer = StandardScaler()\n",
        "X_train = normalizer.fit_transform(X_train)\n",
        "X_test = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "SGfKZgeSCE1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train logistic regression\n",
        "clf = LogisticRegression(penalty='12',C=1.0)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_train_pred = clf.predict(X_train)\n",
        "acc = accuracy_score(y_train, y_train_pred)\n",
        "print(\"training accuracy {}:.4f\".format(acc))"
      ],
      "metadata": {
        "id": "-SH3e93sC1zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate logistic regression\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "print(\"testing accuracy {}:.4f\".format(acc))"
      ],
      "metadata": {
        "id": "Qt9HNsdFDaRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test difference regularization vals\n",
        "\n",
        "regularization_coeff = [0.1, 0.5, 1.0, 5.0]\n",
        "\n",
        "for reg in regularization_coeff:\n",
        "  clf = LogisticRegression(penalty='12',C=reg)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  y_test_pred = clf.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "  print(\"reg coeff: {}, accuracy: {:.3f}\".format(1.0/reg, acc))"
      ],
      "metadata": {
        "id": "bQ3TOpDBD1RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection: Threefold Split\n",
        "\n",
        "```Training Set: ``` used for training during training phase\n",
        "\n",
        "```Validation Set: ``` used for hyperparameter selection during training phase\n",
        "\n",
        "```Testing Set: ``` used for evaluating the model after obtaining the model"
      ],
      "metadata": {
        "id": "cwfvZvWhEfD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros:\n",
        "\n",
        "* Fast & Simple\n",
        "\n",
        "Cons:\n",
        "\n",
        "* Large variance\n",
        "* Wastes data"
      ],
      "metadata": {
        "id": "GBVyIBiWIITg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Threefold split\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y = True)\n",
        "print(X.shape)\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y,\n",
        "                                                            test_size = 0.1,\n",
        "                                                            random_state = 0)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_val,\n",
        "                                                      y_train_val,\n",
        "                                                      test_size = 0.1,\n",
        "                                                      random_state = 0)"
      ],
      "metadata": {
        "id": "61nL1NWTE-o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regularization_coeff = [0.1, 0.5, 1.0, 5.0]\n",
        "\n",
        "best_acc = 0.0\n",
        "best_reg = 0.0\n",
        "\n",
        "#training\n",
        "for reg in regularization_coeff:\n",
        "  clf = LogisticRegression(penalty='12',C=reg)\n",
        "\n",
        "  clf.fit(X_train, y_train) #use training data\n",
        "\n",
        "  y_valid_pred = clf.predict(X_valid) #use validation set\n",
        "  acc = accuracy_score(y_valid, y_valid_pred)\n",
        "\n",
        "  if acc > best_acc:\n",
        "    best_acc = acc\n",
        "    best_reg = reg\n",
        "\n",
        "  print(\"reg coeff: {}, accuracy: {:.3f}\".format(1.0/reg, acc))\n",
        "\n",
        "#evaluation\n",
        "clf = LogisticRegression(penalty='12',C=best_reg)\n",
        "clf.fit(X_train_val, y_train_val)\n",
        "\n",
        "y_test_pred = clf.predict(X_test) #use testing set\n",
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "print(\"acc: {:.3f}\".format(acc))"
      ],
      "metadata": {
        "id": "SAc37t3vF02M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection: Cross-validation\n",
        "\n",
        "Training data: randomly partition into $k$ folds\n",
        "* $k-1$ folds for training set\n",
        "* 1 fold for validation set\n",
        "\n",
        "How to select the model\n",
        "* for each hyperparameter, train the model $k$ times\n",
        "* evaluate the model $k$ times\n",
        "* use the mean of $k$ evaluation to select model\n",
        "\n"
      ],
      "metadata": {
        "id": "6xn_yfiiHHW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros:\n",
        "* More data\n",
        "* More stable\n",
        "\n",
        "Cons:\n",
        "* slower"
      ],
      "metadata": {
        "id": "U9L4wGzxIJd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for reg in regularization_coeff:\n",
        "\n",
        "  sum_acc = 0.0\n",
        "\n",
        "  for fold in range(5):\n",
        "    index_of_folds_temp = index_of_folds.copy()\n",
        "\n",
        "    valid_index = index_of_folds_temp[fold,:].reshape(-1)\n",
        "    train_index = np.delete(index_of_folds_temp, fold, 0).reshape(-1)\n",
        "\n",
        "    X_train = X_train_val[train_index]\n",
        "    y_train = y_train_val[train_index]\n",
        "\n",
        "    X_valid = X_train_val[valid_index]\n",
        "    y_valid = y_train_val[valid_index]\n",
        "\n",
        "    clf = LogisticRegression(penalty='12', C=reg)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_valid_pred = clf.predict(X_valid)\n",
        "    acc = accuracy_score(y_valid, y_valid_pred)\n",
        "\n",
        "    sum_acc += acc\n",
        "\n",
        "  cur_acc = sum_acc / 5.0\n",
        "  print(\"reg coeff: {}, acc: {:.3f}\".format(1.0/reg, cur_acc))\n",
        "\n",
        "  if cur_acc > best_acc:\n",
        "    best_acc = cur_acc\n",
        "    best_reg = reg\n",
        "\n",
        "clf = LogisticRegression(penalty='12',C=best_reg)\n",
        "clf.fit(X_train_val, y_train_val)\n",
        "\n",
        "y_test_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"acc: {:.3f}\".format(acc))"
      ],
      "metadata": {
        "id": "uwxXt2bKIQFR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}