{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Exploratory Data Analysis**\n",
        "\n",
        "  Tabular Data\n",
        "* Numerical features\n",
        " * line plot, hist plot, box plot, scatter plot\n",
        "* Categorical Features: convert to numerical values\n",
        " * bar plot, pie plot\n"
      ],
      "metadata": {
        "id": "VRPzD5nk0kVI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLF8jT4My3bd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('cars.csv')\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#line plot\n",
        "plt.plot(df['Horsepower'])\n",
        "plt.show()\n",
        "\n",
        "#histogram\n",
        "df.hist(bins=50, figsize=(20,15)) #number of bins: number of intervals\n",
        "plt.show()\n",
        "\n",
        "plt.hist(df['MPG'], bins=50)\n",
        "plt.show()\n",
        "\n",
        "#box & whisker plot\n",
        "plt.boxplot(df['Acceleration'], vert=False)\n",
        "plt.show()\n",
        "\n",
        "#scatter plot\n",
        "plt.scatter(df['MPG'], df['weight'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dcsLXA_P20nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Long tail distribution`: Most data values fall far from the center of the distribution (use median value to predict)\n",
        "\n",
        "* `Non-long tail distribution` (use median or mean)"
      ],
      "metadata": {
        "id": "EAJhraTw5Ck6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical features\n",
        "\n",
        "#bar plot\n",
        "df = pd.read_csv('cars.csv')\n",
        "df['Origin'].value_counts().plot(kind = 'bar')\n",
        "plt.show()\n",
        "\n",
        "#pie plot\n",
        "df['Origin'].value_counts().plot(kind = 'pie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AxLcLbSa5RTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temporal Data\n",
        "* trend, seasonality || stock prices, temperature\n",
        " * line plot\n",
        "\n",
        "Spatial Data\n",
        "* changes over space || latitude, longitude\n",
        " * scatter plot\n",
        "\n",
        "Graph Data\n",
        "* networks\n",
        " * nodes"
      ],
      "metadata": {
        "id": "0nQZWDs6HL_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph data (networks):\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "G = nx.erdos_renyi_graph(20, 0.4)\n",
        "\n",
        "print(G.number_of_nodes())\n",
        "print(G.number_of_edges())\n",
        "print(G.degree([1,2]))"
      ],
      "metadata": {
        "id": "52NgUDcC9khz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical features\n",
        "*   Missing items can be assigned the median or mean value\n",
        "\n"
      ],
      "metadata": {
        "id": "EOEBA31WNQ2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find & fill missing values"
      ],
      "metadata": {
        "id": "-HYd_MKiPdlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find missing values\n",
        "\n",
        "df = pd.read_csv('housing.csv')\n",
        "\n",
        "print(df)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "clcY8ceA_DRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'is null' returns a same-sized object indicating T or F if the values are NA\n",
        "df.isnull()\n",
        "df.isnull.sum()"
      ],
      "metadata": {
        "id": "Su_hSqF6MHvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# proportion of missing values\n",
        "print(df.isnull().sum()/df.shape[0])\n",
        "\n",
        "# remove the feature with a lot of missing values\n",
        "df.drop('total_bedrooms', axis=1)\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "wWMbNAKBMJVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill in missing values\n",
        "\n",
        "mean_val = df['total_bedrooms'].mean()\n",
        "median_val = df['total_bedrooms'].median()\n",
        "\n",
        "print(mean_val)\n",
        "print(median_val)\n",
        "\n",
        "df['total_bedrooms'] = df['total_bedrooms'].fillna(mean_val)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "0POfnh0FKrYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mean or median - check distribution\n",
        "\n",
        "plt.hist(df['total_bedrooms'].values, 100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NodxVdqhMFBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical features\n",
        "* can not compute mean or median"
      ],
      "metadata": {
        "id": "DBdM0FKpNMOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# can fill empty categorical features with a new category\n",
        "\n",
        "print(df['ocean_proximity'].unique())\n",
        "\n",
        "filling_value = 'PA'\n",
        "df['ocean_proximity'] = df['ocean_proximity'].fillna(filling_value)\n",
        "\n",
        "print(df['ocean_proximity'].unique())"
      ],
      "metadata": {
        "id": "tevfaZZnNbWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting categorical values to numerical values\n",
        "* `label encoding`: each categorical feature is converted to an integer value\n",
        "* `one-hot encoding`: each category is mapped to a unique vector containing 0, 1\n",
        "* `ordinal encoding`: the category is ordinal; retaining the order is important (e.g., ratings, 1-4 star reviews)"
      ],
      "metadata": {
        "id": "7JxPbYygORMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding"
      ],
      "metadata": {
        "id": "I-CDwNpzPUY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv('housing.csv')\n",
        "print(df['ocean_proximity'].value_counts())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['ocean_proximity'] = label_encoder.fit_transform(df['ocean_proximity'])\n",
        "\n",
        "print(df['ocean_proximity'].value_counts())"
      ],
      "metadata": {
        "id": "eV7KprkpOLty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot Encoding\n",
        "* `v1 = [1, 0, 0]`\n",
        "* `v2 = [0, 1, 0]`\n",
        "* `v3 = [0, 0, 1]`"
      ],
      "metadata": {
        "id": "lTFnADm_PWGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "df = pd.read_csv('housing.csv')\n",
        "print(df['ocean_proximity'][0])\n",
        "\n",
        "onehotencoder = OneHotEncoder(sparse = False)\n",
        "result = onehotencoder.fit_transform(df[['ocean_proximity']])\n",
        "print(result[0,:])\n",
        "\n",
        "#note: dimensionality changes (scalar -> vector)"
      ],
      "metadata": {
        "id": "YRJnkUzZPX9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordinal Encoding\n",
        "\n",
        "* `Poor || 1`\n",
        "* `Good || 2`\n",
        "* `Very Good || 3`\n",
        "* `Excellent || 4`"
      ],
      "metadata": {
        "id": "AzEmLyIIRpmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ordinal encoding\n",
        "import pandas as pd\n",
        "\n",
        "data = {'rating': ['Poor', 'Good', 'Very Good', 'Excellent']}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "coding_map = {'Poor': 1, 'Good':2, 'Very Good': 3, 'Excellent': 4}\n",
        "df['rating'] = df.rating.map(coding_map)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "qNZ7aeojSG6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling\n",
        "* different features have different scales / magnitudes"
      ],
      "metadata": {
        "id": "0CUF1sBMT19p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Min-max Normalization\n",
        "* sensitive to outliers"
      ],
      "metadata": {
        "id": "Km9oxY1iUVt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "df = pd.read_csv('housing.csv')\n",
        "X = df.values[0:5, 5:9].astype(dtype=np.float32)\n",
        "# original data\n",
        "print(X)\n",
        "\n",
        "x_min = X.min(axis=0)\n",
        "x_max = X.max(axis=0)\n",
        "\n",
        "# min and max\n",
        "print(x_min)\n",
        "print(x_max)\n",
        "\n",
        "# scaling data\n",
        "X = (X-x_min)/(x_max-x_min)\n",
        "print(X)"
      ],
      "metadata": {
        "id": "E3qwKRPoUXc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z-score normalization (Standardization)\n",
        "* good for normal distribution"
      ],
      "metadata": {
        "id": "cRiMJLbmVUel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('housing.csv')\n",
        "X = df.values[0:5, 5:9].astype(dtype=np.float32)\n",
        "# original data\n",
        "print(X)\n",
        "\n",
        "# mean and std\n",
        "x_mean = np.mean(X, axis=0)\n",
        "x_std = np.std(X, axis=0)\n",
        "\n",
        "# scaling data\n",
        "X = (X-x_mean)/x_std\n",
        "print(X)"
      ],
      "metadata": {
        "id": "E_GdJO-JVayO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}