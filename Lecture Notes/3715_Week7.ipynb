{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**K-nearest Neighbor Algorithm**\n",
        "\n",
        "* supervised learning model\n",
        "\n",
        "* non-parametric model\n",
        "  * Do not need to learn model parameters (w)\n",
        "  * Assume some functional form (Gaussian, Bernoulli, logistic, linear, quadratic) for P(Y|X)\n",
        "\n",
        "\n",
        "Basic Idea:\n",
        "* Find the k nearest neighbors of sample x\n",
        "* Find the majority category label within these neighbors\n",
        "* Assign the majority label to sample x\n",
        "___\n",
        "Pros:\n",
        "* Fast training\n",
        "* Easy to understand and implement\n",
        "\n",
        "Cons:\n",
        "* Testing is slow\n",
        "* Curse of dimensionality\n",
        "* Need adequate distance measure\n",
        "___"
      ],
      "metadata": {
        "id": "hQizRtQi3q1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to find neighbors?\n",
        "\n",
        "* Euclidean distance (l2 norm)\n",
        "\n",
        "  $d = ||x-y||_2 = \\sqrt{(x_1-y_1)^2 + (x_2-y_2)^2 + ... + (x_d - y_d)^2}$\n",
        "* Manhattan distance (l1 norm)\n",
        "* Correlation"
      ],
      "metadata": {
        "id": "6fX1H1O74tOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#comparison with linear regression\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "k_range = range(1,5)\n",
        "param_grid = dict(n_neighbors = k_range)\n",
        "\n",
        "grid = GridSearchCV(clf_knn, param_grid, cv = 5, scoring = 'accuracy')\n",
        "grid.fit(Xtr, Ytr)\n",
        "\n",
        "print(grid.best_score_)\n",
        "print(grid.best_params_)\n",
        "\n",
        "#----testing----\n",
        "clf_lr = LogisticRegression(penalty = '12', C = grid.best_params_['C'])\n",
        "clf_lr.fit(Xtr, Ytr)\n",
        "\n",
        "y_pred = clf_lr.predict(Xte)\n",
        "\n",
        "acc = accuracy_score(Yte, y_pred)\n",
        "macro_f1 = f1_score(Yte, y_pred, average = 'macro')\n",
        "micro_f1 = f1_score(Yte, y_pred, average = 'micro')\n",
        "\n",
        "print(acc, macro_f1, micro_f1)"
      ],
      "metadata": {
        "id": "bphvhpBv52Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Clustering**\n",
        "* Unsupervised learning (given samples, no labels)\n",
        "* Clustering: find meaningful groups of samples such that samples in the same group are similar & samples in different groups are dissimilar"
      ],
      "metadata": {
        "id": "qOczAad966TV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Partition Methods**\n",
        "* construct various partitions and then evaluate by some criterion\n",
        "  * K-means (assume k groups, compute mean for each cluster)\n",
        "  * Gaussian mixture model\n",
        "  * Spectral clustering (map samples in a different space to partition groups more easily)\n",
        "\n",
        "**Hierarchical Methods**\n",
        "* create a hierarchical decomposition of the set of objects using some criterion\n",
        "  * Bottom-up - agglomerative\n",
        "  * Top-down - divisive"
      ],
      "metadata": {
        "id": "wOduHQ1u8lLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**K-means**\n",
        "\n",
        "Given a dataset ${x_1,x_2,...,x_n}$, k means partitions it into k clusters\n",
        "* each cluster has a cluster center called a centroid\n",
        "* k is specified by the user\n",
        "\n",
        "Steps:\n",
        "1. Randomly initialize the cluster centroid $\\mu_1, \\mu_2, ..., \\mu_k$\n",
        "2. Repeat until no change in $\\mu_i$\n",
        "  \n",
        "  2.1 Classify n samples in terms of the nearest cluster centroid\n",
        "  \n",
        "  2.2 Recompute the cluster centroid\n",
        "____\n",
        "Pros:\n",
        "* Easy to implement\n",
        "* Efficient: O(KNT)\n",
        "  * K = number of clusters\n",
        "  * N = number of samples\n",
        "  * T = number of iterations\n",
        "\n",
        "Cons:\n",
        "* Only applicable when the mean is defined\n",
        "* Sensitive to outliers\n",
        "* Sensitive to initialization\n",
        "____"
      ],
      "metadata": {
        "id": "9mTEchMy-O1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Agglomerative Clustering**\n",
        "* Bottom-up approach\n",
        "\n",
        "* Each sample is a cluster\n",
        "* Repeat:\n",
        "  * Pick the two closest clusters\n",
        "  * Merge them into a new cluster\n",
        "  * Stop when there is only one cluster left\n",
        "\n",
        "\n",
        "**How to measure the similarity between two clusters?**\n",
        "\n",
        "____\n",
        "1. Single Link:\n",
        "- distance of two closest samples in each cluster\n",
        "- potentially long and skinny clusters\n",
        "\n",
        "  $C_1 = \\{x_1,x_2\\}$,\n",
        "  $C_2 = \\{y_1,y_2\\}$\n",
        "\n",
        "  calculate distance of all pairs, find the smallest distance\n",
        "\n",
        "  $Dist(C_1,C_2) = min||x-y||$\n",
        "\n",
        "______\n",
        "2. Complete Link:\n",
        "- distance of two farthest samples in each cluster\n",
        "- gives tighter clusters\n",
        "\n",
        "  calculate distance of all pairs, find the largest distance\n",
        "\n",
        "  $Dist(C_1,C_2) = max||x-y||$\n",
        "\n",
        "___\n",
        "3. Average Link\n",
        "- average distance of all pairs\n",
        "- robust against noise\n",
        "- most widely used method\n",
        "____"
      ],
      "metadata": {
        "id": "xgj6tsJlDt7f"
      }
    }
  ]
}