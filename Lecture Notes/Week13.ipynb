{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Convolutional Neural Network**"
      ],
      "metadata": {
        "id": "XG0i-ekgHdbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- locally connected neural network (uses filters/kernels)\n",
        "\n",
        "**Feature extractor**: Learn useful features from images for prediction\n",
        "\n",
        "  Sobel Filter: weights to detect horizontal, vertical edges (3x3 matrix)\n"
      ],
      "metadata": {
        "id": "SX7zQ1D1HlJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Convolution\n",
        "\n",
        "- Matrix inner product\n",
        "\n",
        "\n",
        "```\n",
        "A = [1, 3]   B = [5, 7]\n",
        "    [2, 4]       [6, 8]\n",
        "```\n",
        "inner product = $\\sum{}\\sum{} a_{ij}b_{ij}$ =   70\n",
        "\n",
        "Input image + Filter (Kernel) --Convolution--> Result\n",
        "\n",
        "values in the resuting matrix are the inner product of the input image patch and the filter\n",
        "\n",
        "size of the resulting matrix:\n",
        "\n",
        "input: $d_1 × d_2$\n",
        "\n",
        "filter: $k_1\\times k_2$\n",
        "\n",
        "output: $(d_1-k_1+1)\\times(d_2-k_2+1)$\n",
        "\n",
        "\n",
        "###**Zero padding**\n",
        "\n",
        "Problem: the output is snaller than the input\n",
        "\n",
        "Solution: use zero padding\n",
        "- keep the next layer's width and height consistent with the previous one\n",
        "- keep information about the border of the image\n",
        "\n",
        "Steps:\n",
        "- add a border of all zeros around the image\n",
        "- increase the imput shape from $d_1 \\times d_2$ to $(d_1 + 2) \\times (d_2 +2)$\n",
        "- if the filter is 3x3 , the output is $d_1 \\times d_2$\n",
        "\n",
        "###Stride\n",
        "- 'step size'\n",
        "- the filter moves K steps each time, K $\\ge$ 1\n",
        "- larger stride -> smaller output feature map\n",
        "\n",
        "input: $d_1 × d_2$\n",
        "\n",
        "filter: $k_1\\times k_2$\n",
        "\n",
        "stride: $s$\n",
        "\n",
        "output: $(\\frac{d_1-k_1}{s}+1)\\times(\\frac{d_2-k_2}{s}+1)$ ; integer division (//)\n",
        "\n",
        "**Convolutional layer**:\n",
        "\n",
        "$x_j^l = f(\\sum{conv(x_i^{l-1}, k_{ij}^l) + b_j^l})$\n",
        "\n",
        "- $x_j$ is the $j$-th feature map in the $l$-th layer\n",
        "\n",
        "- $k_{ij}^l$ is the convolutional kernel in the $l$-th layer\n",
        "\n",
        "RGB channels\n",
        "\n",
        "3 input feature maps ---6 filters---> 2 output feature maps\n",
        "\n",
        "num of filters: (num input feature maps $\\times$ num of output feature maps)\n",
        "\n",
        "\n",
        "how many trainable weights?: num filters $\\times$ filter dimensions\n",
        "\n",
        "**Pooling Layer**\n",
        "\n",
        "- Reduce the dimensionality of each feature map\n",
        "- Max pooling, mean pooling\n"
      ],
      "metadata": {
        "id": "4jOtO_VuIy-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Recurrent Neural Network**\n",
        "- used for sequential data, e.g., review classification, machine translation, speech recognition\n",
        "\n",
        "Key idea: an 'internal state' that is updated as a sequence is processed\n",
        "\n",
        "Input -> Hidden state (captures dependence across words) -> Output\n",
        "\n",
        "update hidden state:\n",
        "\n",
        "Process a sequence of vectors x by applying a recurrence formula at each time step\n",
        "\n",
        "$h_t = f_W(h_{t-1}, x_t)$\n",
        "\n",
        "$h_t$ = new state\n",
        "\n",
        "$f_W$ = some function with parameters W\n",
        "\n",
        "$h_{t-1}$ = old state\n",
        "\n",
        "$x_t$ = input vector at some time step\n",
        "\n",
        "$h_t = tanh(W_{hh}h_{t-1}+W_{xh}x_t)$\n",
        "\n",
        "two inputs: time state information, input feature"
      ],
      "metadata": {
        "id": "nz5qIn2Mb-jg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forward pass**\n",
        "\n",
        "$h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t)$\n",
        "\n",
        "**Examples**\n",
        "- sentiment classification: many to one\n",
        "  - input: 1+ sentences\n",
        "  - output: positive or negative class\n",
        "\n",
        "- image captioning: one to many\n",
        "  - input: image features\n",
        "  - output: a sentence describing the image\n",
        "\n",
        "- character prediction: many to many\n",
        "  - predict the next character/word\n",
        "\n",
        "\n",
        "###**Long Short-Term Memory (LSTM)**\n",
        "\n",
        "- captures long-term dependencies\n",
        "- components:\n",
        "  - memory cell $c_t$\n",
        "  - forget gate $f_t$\n",
        "  - input gate $i_t$\n",
        "  - output gate $o_t$\n",
        "  - output $h_t$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "81TmujYigVbj"
      }
    }
  ]
}