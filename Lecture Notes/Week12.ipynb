{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**Page Rank**\n",
        "\n",
        "**$p(t)$** is a probability distribution over pages\n",
        "\n",
        "$p(t+1) = M*p(t)$ 'Random walk'\n",
        "\n",
        "$ r_{t+1} = Mr_t$\n",
        "\n",
        "r is the eigenvector of the transition matrix M (with eigenvalue 1)\n",
        "\n",
        "\n",
        "Solution of the importance score r:\n",
        "- compute the eigenvector of the transition matrix M with eigenvaue 1\n",
        "- use power iteration to compute the eigenvector efficiently\n",
        "\n",
        "- assign each node an initial page rank\n",
        "- repeat until convergence $\\sum{|{r_i^{t+1}-r_i^t}|} < ϵ$\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qsrIv_oBEE4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Neural Networks**\n",
        "\n",
        "- Fully-connected neural network: multi-layer perceptron (MLP)\n",
        "- Convolutional neural network - most widely used for image classification\n",
        "- Recurrent neural network - most widely used with temporal data (e.g., weather)\n",
        "\n",
        "Layer 1: $z_i^{(1)} = W^{(0)}x_i$\n",
        "\n",
        "Layer 2: $z_i^{(2)} = W^{(1)}z_i^{(1)}$\n",
        "\n",
        "Layer 3: $z_i^{(3)} = W^{(2)}z_i^{(2)}$\n",
        "\n",
        "...\n",
        "\n",
        "Layer L: $z_i^{(L)} = W^{(L-1)}z_i^{(L-1)}$\n"
      ],
      "metadata": {
        "id": "ovG9-qpjLxz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation function**: introduces non-linearity\n",
        "\n",
        "ex) sigmoid, tanh, ReLu, leaky ReLu\n",
        "\n",
        "\n",
        "Layer 1: $z_i^{(1)} = W^{(0)}x_i$\n",
        "\n",
        "Layer 2: $z_i^{(2)} = W^{(1)}h_i^{(1)}$; $h_i^{(1)} = σ(z_i^{(1)})$\n",
        "\n",
        "Layer 3: $z_i^{(3)} = W^{(2)}h_i^{(2)}$; $h_i^{(2)} = σ(z_i^{(2)})$\n",
        "\n",
        "...\n",
        "\n",
        "Layer L: $z_i^{(L)} = W^{(L-1)}h_i^{(L-1)}$; $h_i^{(L-1)} = σ(z_i^{(L-1)})$"
      ],
      "metadata": {
        "id": "oCLATev2dv5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use stochastic gradient descent to learn model parameters\n",
        "\n",
        "for linear model: $W_{t+1} = W_t - η\\frac{\\partial L}{\\partial W}f(W_t)$\n",
        "\n",
        "Optimization: use backpropagation!\n",
        "\n",
        "$h(x) = f(g(x))$\n",
        "\n",
        "Chain rule:\n",
        "$\\frac{\\partial h(x)}{\\partial x} = \\frac{\\partial f(g)}{\\partial g} \\frac{\\partial g(x)}{\\partial x}$\n",
        "\n"
      ],
      "metadata": {
        "id": "s48dmV0chlAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(28*28, 256) #linear layer (784 -> 256)\n",
        "    self.fc2 = nn.Linear(256,128) #linear layer (256 -> 128)\n",
        "    self.fc3 = nn.Linear(128,10) #linear layer (128 -> 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = x.view(-1, 28*28) #input layer\n",
        "    h1 = F.relu(self.fc1(h0)) #hidden layer 1\n",
        "    h2 = F.relu(self.fc2(h1)) #hidden layer 2\n",
        "    h3 = self.fc3(h2) #output layer\n",
        "\n",
        "    return h3\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = args['lr'])\n"
      ],
      "metadata": {
        "id": "UvS9CIsDoXAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "  data, target = data.cuda(), target.cuda()\n",
        "\n",
        "  #forward pass\n",
        "  output = model(data)\n",
        "  #backward pass\n",
        "  loss = criterion(output, target)\n",
        "\n",
        "  #compute gradients\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  #update parameters\n",
        "  optimizer.step()\n",
        "\n",
        "  #print loss periodically\n",
        "  if batch_idx % args['log interval'] == 0:\n",
        "    print(\"Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "metadata": {
        "id": "BSAwJedYW4S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "for data, target in test_loader:\n",
        "  data, target = data.cuda(), target.cuda()\n",
        "\n",
        "  output = model(data)\n",
        "  test_loss += criterion(output, target)\n",
        "  pred = output.data.max(1, keepdim = True)[1]\n",
        "  correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print(\"\\nTest set | Average Loss: {:.4f}, Accuracy: {}/{} ({:.0f})\\n\".format(\n",
        "    test_loss, correct, len(test_loader.dataset), 100. * correct/ len(test_loader.dataset)))\n"
      ],
      "metadata": {
        "id": "acQNPzamW4-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}